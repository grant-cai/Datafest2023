{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73bcd7ac-3fba-4de2-a223-d649e8633905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3747f32b-49d7-4182-bbc4-0719b7e1b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v7/ql1hlrjn2556687_hypw44180000gn/T/ipykernel_14594/804447124.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  qposts = pd.read_csv(\"/Users/jessie/Desktop/UCSB/datafest_data/data/questionposts.csv\", on_bad_lines = \"skip\")\n"
     ]
    }
   ],
   "source": [
    "qposts = pd.read_csv(\"/Users/jessie/Desktop/UCSB/datafest_data/data/questionposts.csv\", on_bad_lines = \"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5911c698-ad76-4cf4-abe9-9e9771ba2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qposts['clean_text'] = qposts['PostText'].replace(r'[^\\w\\s]+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd4b344-f40e-4a79-a0cc-ebe58c0a5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "qposts = qposts.drop(columns=['PostText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c387766a-ed50-4fa1-9d3f-84db688582a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_rows = qposts[qposts['StateAbbr'] == 'PA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cab13d47-1539-47bc-bc0b-06fde6bc918e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>StateAbbr</th>\n",
       "      <th>QuestionUno</th>\n",
       "      <th>CreatedUtc</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243280</th>\n",
       "      <td>270388</td>\n",
       "      <td>PA</td>\n",
       "      <td>1E5252EE-5902-4CE7-A082-3496A82EBE43</td>\n",
       "      <td>2021-06-17 15:46:19</td>\n",
       "      <td>On  our landlord informed us she was sell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243281</th>\n",
       "      <td>270389</td>\n",
       "      <td>PA</td>\n",
       "      <td>1E5252EE-5902-4CE7-A082-3496A82EBE43</td>\n",
       "      <td>2021-07-01 23:15:48</td>\n",
       "      <td>I dont think you should focus on the extension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243282</th>\n",
       "      <td>270390</td>\n",
       "      <td>PA</td>\n",
       "      <td>00588C4E-B254-469C-9102-92B4BEBAB5B8</td>\n",
       "      <td>2021-06-17 16:45:19</td>\n",
       "      <td>I was with someone for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243283</th>\n",
       "      <td>270391</td>\n",
       "      <td>PA</td>\n",
       "      <td>00588C4E-B254-469C-9102-92B4BEBAB5B8</td>\n",
       "      <td>2021-07-08 14:32:50</td>\n",
       "      <td>Since your name is not on the deed you are not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243284</th>\n",
       "      <td>270392</td>\n",
       "      <td>PA</td>\n",
       "      <td>93A7EA49-A15D-483C-AD9D-E747B24E329A</td>\n",
       "      <td>2021-06-17 19:23:21</td>\n",
       "      <td>I took out personal loan and used my truck as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244100</th>\n",
       "      <td>271293</td>\n",
       "      <td>PA</td>\n",
       "      <td>C742C1C2-BE7F-426A-B807-FB4AEA1BB059</td>\n",
       "      <td>2022-01-07 16:29:58</td>\n",
       "      <td>My landlord  received  money from the program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244101</th>\n",
       "      <td>271294</td>\n",
       "      <td>PA</td>\n",
       "      <td>A06CD09F-A415-4801-8AB9-C1D87F1D92CB</td>\n",
       "      <td>2022-01-08 01:45:04</td>\n",
       "      <td>M y uncle illegally took over my  estate becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244102</th>\n",
       "      <td>271295</td>\n",
       "      <td>PA</td>\n",
       "      <td>04FA24DC-D1BF-4225-96A8-8A9A70FE26B3</td>\n",
       "      <td>2022-01-08 01:50:05</td>\n",
       "      <td>My mother has dementia and and I am about to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244103</th>\n",
       "      <td>271296</td>\n",
       "      <td>PA</td>\n",
       "      <td>B552323D-02D8-406D-9C60-1263818ACC2F</td>\n",
       "      <td>2022-01-08 01:54:04</td>\n",
       "      <td>Mr  has already sold one of the homes that wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244104</th>\n",
       "      <td>271297</td>\n",
       "      <td>PA</td>\n",
       "      <td>8FC01478-D2A2-46D3-955B-7EDC0D0E1875</td>\n",
       "      <td>2022-01-08 18:14:15</td>\n",
       "      <td>I am a  old college student This past year I s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>825 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id StateAbbr                           QuestionUno  \\\n",
       "243280  270388        PA  1E5252EE-5902-4CE7-A082-3496A82EBE43   \n",
       "243281  270389        PA  1E5252EE-5902-4CE7-A082-3496A82EBE43   \n",
       "243282  270390        PA  00588C4E-B254-469C-9102-92B4BEBAB5B8   \n",
       "243283  270391        PA  00588C4E-B254-469C-9102-92B4BEBAB5B8   \n",
       "243284  270392        PA  93A7EA49-A15D-483C-AD9D-E747B24E329A   \n",
       "...        ...       ...                                   ...   \n",
       "244100  271293        PA  C742C1C2-BE7F-426A-B807-FB4AEA1BB059   \n",
       "244101  271294        PA  A06CD09F-A415-4801-8AB9-C1D87F1D92CB   \n",
       "244102  271295        PA  04FA24DC-D1BF-4225-96A8-8A9A70FE26B3   \n",
       "244103  271296        PA  B552323D-02D8-406D-9C60-1263818ACC2F   \n",
       "244104  271297        PA  8FC01478-D2A2-46D3-955B-7EDC0D0E1875   \n",
       "\n",
       "                 CreatedUtc                                         clean_text  \n",
       "243280  2021-06-17 15:46:19       On  our landlord informed us she was sell...  \n",
       "243281  2021-07-01 23:15:48  I dont think you should focus on the extension...  \n",
       "243282  2021-06-17 16:45:19                          I was with someone for     \n",
       "243283  2021-07-08 14:32:50  Since your name is not on the deed you are not...  \n",
       "243284  2021-06-17 19:23:21  I took out personal loan and used my truck as ...  \n",
       "...                     ...                                                ...  \n",
       "244100  2022-01-07 16:29:58  My landlord  received  money from the program ...  \n",
       "244101  2022-01-08 01:45:04  M y uncle illegally took over my  estate becau...  \n",
       "244102  2022-01-08 01:50:05  My mother has dementia and and I am about to b...  \n",
       "244103  2022-01-08 01:54:04  Mr  has already sold one of the homes that wer...  \n",
       "244104  2022-01-08 18:14:15  I am a  old college student This past year I s...  \n",
       "\n",
       "[825 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deabbbc1-262c-45b0-8474-93aec88d9466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jessie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d97284a-912d-475d-b1b4-ffe6c538b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_remove_stopwords(text):\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords from the tokens\n",
    "    filtered_tokens = [word for word in tokens if not word in stopwords.words()]\n",
    "    \n",
    "    # Return the filtered tokens as a list\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5e30dd0-9fda-47bd-b205-69201c05689a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qposts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mqposts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_and_remove_stopwords\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtokenize_and_remove_stopwords\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_and_remove_stopwords\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Tokenize the text into words\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m word_tokenize(\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m())\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Remove stopwords from the tokens\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     filtered_tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m stopwords\u001b[38;5;241m.\u001b[39mwords()]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "qposts['filtered_tokens'] = qposts['clean_text'].apply(tokenize_and_remove_stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
